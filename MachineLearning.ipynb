{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset do složky DataSet -- Dataset1\n",
    "#                           |- Dataset2\n",
    "\n",
    "# Rozdělit Dataset na 2-3 Train, Test, Validation \n",
    "# Validation je až poslední\n",
    "# shuffle data \n",
    "# balance data nemít 40% stejnou ground truth (tohle je asi u classifierů)\n",
    "\n",
    "#### DEFINE DataLoader ####\n",
    "\n",
    "class data(Dataset):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path  # check if exists\n",
    "        self.files = os.listdir(path)\n",
    "\n",
    "    # the function returns length of data\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    # gives one item at a time\n",
    "    def __getitem__(self, index):\n",
    "        # OPEN JSON -> LOAD IMAGE PATHS  | probably set to grayscale\n",
    "        #           -> LOAD GROUND TRUTH | probably change format\n",
    "        filename = self.files[index]\n",
    "        DatasetItem = json.load(open(os.path.join(self.path, filename)))\n",
    "\n",
    "        convert_tensor = transforms.ToTensor()\n",
    "\n",
    "\n",
    "        src = cv2.imread(DatasetItem['src'], cv2.IMREAD_GRAYSCALE)\n",
    "        src = cv2.resize(src, (240, 135))\n",
    "        src = convert_tensor(src) \n",
    "\n",
    "        dst = cv2.imread(DatasetItem['dst'], cv2.IMREAD_GRAYSCALE)\n",
    "        dst = cv2.resize(dst, (240, 135))\n",
    "        dst = convert_tensor(dst) \n",
    "\n",
    "        groundTruth = torch.tensor(DatasetItem['transformation'])\n",
    "\n",
    "        stacked = torch.stack((src, dst))\n",
    "        return stacked, groundTruth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINE Neural Network ####\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self._to_linear = None\n",
    "\n",
    "        # 2 input image channel, 64 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc9 = nn.Linear(64800, 1024)\n",
    "\n",
    "        self.fc10 = nn.Linear(1024, 6)\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        # 240 x 135\n",
    "        # two conv layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # max pooling\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # 120 x \n",
    "        # two conv layers\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        # max pooling\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # 60 x \n",
    "        # two conv layers\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        # max pooling\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # 30 x \n",
    "        # two conv layers\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self.convs(x)\n",
    "        x = x.view(-1, x[0].shape[0] * x[0].shape[1] * x[0].shape[2])\n",
    "\n",
    "        # two linear layers\n",
    "        x = self.fc9(x)\n",
    "        x = self.fc10(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4362,  0.2902, -0.4116,  0.2534, -0.1030,  0.0130],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#### Create data ####\n",
    "\n",
    "Dataset = data('.\\\\..\\\\Data\\MachineData')\n",
    "# TODO split data set (better)\n",
    "train_set, val_set = torch.utils.data.random_split(Dataset, [154,30])\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Parameters\n",
    "train_dataloader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(val_set, batch_size=3, shuffle=True)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    Images, GTtransformations = batch\n",
    "    output = net(Images.view(-1, 2, 240, 135))\n",
    "    print(output[0])\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss() # TODO better loss\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Epochs = 3\n",
    "# # Loop over epochs\n",
    "# for epoch in range(Epochs):\n",
    "#     for data in train_dataloader:\n",
    "#         Images, GTtransformations = data\n",
    "#         net.zero_grad()  \n",
    "#         output = net(Images.view(-1,1920, 1080)) \n",
    "#         loss = F.nll_loss(output, GTtransformations) # TODO \n",
    "#         loss.backward() \n",
    "#         optimizer.step() \n",
    "#     # Training"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80ad2661c0395a55811b5bbc0e39cc08632ac29b6da55b1bc4258bf36ca6a154"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
